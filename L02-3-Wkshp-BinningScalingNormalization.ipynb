{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Lesson 2 - Data Retrieval and Preparation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning, Scaling and Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning the Continuous Variable into Bins\n",
    "\n",
    "Let's say we have a dataset that contains subject ages. Rather than analyze the ages individually, we would like to group them into the following bins: \n",
    "- Under 20\n",
    "- 20 to 40\n",
    "- 40 to 60\n",
    "- Over 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the pandas cut function to separate this list into bins. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x = list to cut  \n",
    "- bins = number of equal sized bins to create\n",
    "- right = Indicates whether the bins include the rightmost edge or not. If right == True (the default), then the bins [1,2,3,4] indicate (1,2], (2,3], (3,4]  \n",
    "- labels = optional list of labels for each bin\n",
    "\n",
    "Let's first create the data we need: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ages = [20, 22, 25, 27, 21, 23, 37, 31, 61, 45, 41, 32]\n",
    "bins = [18, 25, 35, 60, 100]\n",
    "bin_names = ['Youth', 'YoungAdult', 'MiddleAge', 'Senior']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the cut function to cut our list into labeled bins: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_cats = pd.cut(ages, bins,labels=bin_names)\n",
    "\n",
    "pd.value_counts(new_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zscore normalization\n",
    "\n",
    "Zscaling allows us to transform features so that they have a standard normal distribution with a mean of zero and a standard deviation of 1. \n",
    "\n",
    "We can use sklearns preprocessing.scale method to scale input dataframes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize the data attributes for the Iris dataset.\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# load the Iris dataset\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data and target attributes\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# standardize the data attributes and cast to dataframe\n",
    "standardized_X = pd.DataFrame(preprocessing.scale(X))\n",
    "standardized_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Scaling: Scale to between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Copy the iris data for min-max scaling\n",
    "data_minmax = X.copy()\n",
    "\n",
    "# Scale on the copied data and display the first 5 rows\n",
    "data_minmax = pd.DataFrame(min_max_scaler.fit_transform(data_minmax))\n",
    "data_minmax.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data\n",
    "We can also use sklearn's normalize function to tranform values to a range from 0 to 1 on a sample basis, rather than on a feature basis as seen in scaling methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data attributes for the Iris dataset.\n",
    "\n",
    "# Copy the irisn data for normalizing\n",
    "X2 = X.copy()\n",
    "\n",
    "# normalize the data attributes and display the first 5 rows\n",
    "normalized_X = pd.DataFrame(preprocessing.normalize(???))\n",
    "normalized_X.???()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Consider this\n",
    "How do the values compare between z-scaling, min-max scaling, and normalizing? Use the `describe` method on the created dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
